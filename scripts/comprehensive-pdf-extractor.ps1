# ç»¼åˆPDFå†…å®¹æå–è„šæœ¬
# åŠŸèƒ½ï¼šæå–PDFä¸­çš„æ–‡å­—ã€å›¾è¡¨ã€å›¾ç‰‡ç­‰æ‰€æœ‰å†…å®¹ï¼Œåˆ†ç±»ä¿å­˜

param(
    [Parameter(Mandatory=$true)]
    [string]$PdfPath,
    [string]$OutputDir = "pdf_extracted_content",
    [switch]$ExtractImages = $true,
    [switch]$ExtractText = $true,
    [switch]$ExtractTables = $true,
    [switch]$GenerateReport = $true
)

# æ£€æŸ¥å¿…è¦çš„Pythonåº“
function Test-PythonLibraries {
    Write-Host "æ£€æŸ¥Pythonç¯å¢ƒå’Œå¿…è¦åº“..." -ForegroundColor Yellow
    
    $libraries = @(
        "PyPDF2",
        "pdfplumber", 
        "pdf2image",
        "Pillow",
        "pandas",
        "tabula-py",
        "camelot-py[cv]",
        "pdfminer.six",
        "matplotlib",
        "opencv-python"
    )
    
    $missingLibs = @()
    
    foreach ($lib in $libraries) {
        try {
            $result = python -c "import $($lib.Split('[')[0].Replace('-', '_').Replace('.', '_')); print('OK')" 2>$null
            if ($result -ne "OK") {
                $missingLibs += $lib
            }
        }
        catch {
            $missingLibs += $lib
        }
    }
    
    if ($missingLibs.Count -gt 0) {
        Write-Host "ç¼ºå°‘ä»¥ä¸‹Pythonåº“ï¼Œæ­£åœ¨å®‰è£…..." -ForegroundColor Red
        foreach ($lib in $missingLibs) {
            Write-Host "å®‰è£… $lib..." -ForegroundColor Yellow
            pip install $lib
        }
    }
    
    Write-Host "Pythonç¯å¢ƒæ£€æŸ¥å®Œæˆ" -ForegroundColor Green
}

# åˆ›å»ºè¾“å‡ºç›®å½•ç»“æ„
function New-OutputDirectories {
    param([string]$BaseDir)
    
    $directories = @(
        "$BaseDir\text",
        "$BaseDir\images", 
        "$BaseDir\tables",
        "$BaseDir\charts",
        "$BaseDir\metadata",
        "$BaseDir\reports"
    )
    
    foreach ($dir in $directories) {
        if (!(Test-Path $dir)) {
            New-Item -ItemType Directory -Path $dir -Force | Out-Null
            Write-Host "åˆ›å»ºç›®å½•: $dir" -ForegroundColor Green
        }
    }
}

# ç”ŸæˆPythonæå–è„šæœ¬
function New-PythonExtractorScript {
    param([string]$ScriptPath)
    
    $pythonScript = @"
import os
import sys
import json
import pandas as pd
import pdfplumber
import PyPDF2
from pdf2image import convert_from_path
from PIL import Image
import tabula
import camelot
from pdfminer.high_level import extract_text
from pdfminer.layout import LAParams
import matplotlib.pyplot as plt
import cv2
import numpy as np
from datetime import datetime
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class ComprehensivePDFExtractor:
    def __init__(self, pdf_path, output_dir):
        self.pdf_path = pdf_path
        self.output_dir = output_dir
        self.metadata = {
            'extraction_time': datetime.now().isoformat(),
            'pdf_file': os.path.basename(pdf_path),
            'total_pages': 0,
            'extracted_items': {
                'text_files': [],
                'images': [],
                'tables': [],
                'charts': []
            }
        }
        
    def extract_metadata(self):
        """æå–PDFå…ƒæ•°æ®"""
        try:
            with open(self.pdf_path, 'rb') as file:
                pdf_reader = PyPDF2.PdfReader(file)
                self.metadata['total_pages'] = len(pdf_reader.pages)
                
                if pdf_reader.metadata:
                    self.metadata['pdf_metadata'] = {
                        'title': pdf_reader.metadata.get('/Title', ''),
                        'author': pdf_reader.metadata.get('/Author', ''),
                        'subject': pdf_reader.metadata.get('/Subject', ''),
                        'creator': pdf_reader.metadata.get('/Creator', ''),
                        'producer': pdf_reader.metadata.get('/Producer', ''),
                        'creation_date': str(pdf_reader.metadata.get('/CreationDate', '')),
                        'modification_date': str(pdf_reader.metadata.get('/ModDate', ''))
                    }
                    
            logger.info(f"PDFå…ƒæ•°æ®æå–å®Œæˆï¼Œæ€»é¡µæ•°: {self.metadata['total_pages']}")
            
        except Exception as e:
            logger.error(f"æå–PDFå…ƒæ•°æ®å¤±è´¥: {e}")
            
    def extract_text_content(self):
        """æå–æ–‡æœ¬å†…å®¹"""
        logger.info("å¼€å§‹æå–æ–‡æœ¬å†…å®¹...")
        
        try:
            # æ–¹æ³•1: ä½¿ç”¨pdfplumberæå–ç»“æ„åŒ–æ–‡æœ¬
            with pdfplumber.open(self.pdf_path) as pdf:
                full_text = ""
                page_texts = {}
                
                for i, page in enumerate(pdf.pages, 1):
                    page_text = page.extract_text()
                    if page_text:
                        page_texts[f"page_{i}"] = page_text
                        full_text += f"\n\n=== ç¬¬ {i} é¡µ ===\n\n{page_text}"
                        
                        # ä¿å­˜å•é¡µæ–‡æœ¬
                        page_file = os.path.join(self.output_dir, 'text', f'page_{i:03d}.txt')
                        with open(page_file, 'w', encoding='utf-8') as f:
                            f.write(page_text)
                        self.metadata['extracted_items']['text_files'].append(f'page_{i:03d}.txt')
                
                # ä¿å­˜å®Œæ•´æ–‡æœ¬
                full_text_file = os.path.join(self.output_dir, 'text', 'full_text.txt')
                with open(full_text_file, 'w', encoding='utf-8') as f:
                    f.write(full_text)
                    
                # ä¿å­˜ç»“æ„åŒ–æ–‡æœ¬æ•°æ®
                structured_file = os.path.join(self.output_dir, 'text', 'structured_text.json')
                with open(structured_file, 'w', encoding='utf-8') as f:
                    json.dump(page_texts, f, ensure_ascii=False, indent=2)
                    
                self.metadata['extracted_items']['text_files'].extend(['full_text.txt', 'structured_text.json'])
                
            # æ–¹æ³•2: ä½¿ç”¨pdfmineræå–æ›´è¯¦ç»†çš„æ–‡æœ¬
            detailed_text = extract_text(self.pdf_path, laparams=LAParams())
            detailed_file = os.path.join(self.output_dir, 'text', 'detailed_text.txt')
            with open(detailed_file, 'w', encoding='utf-8') as f:
                f.write(detailed_text)
            self.metadata['extracted_items']['text_files'].append('detailed_text.txt')
            
            logger.info(f"æ–‡æœ¬æå–å®Œæˆï¼Œå…±æå– {len(page_texts)} é¡µ")
            
        except Exception as e:
            logger.error(f"æ–‡æœ¬æå–å¤±è´¥: {e}")
            
    def extract_images(self):
        """æå–å›¾ç‰‡å†…å®¹"""
        logger.info("å¼€å§‹æå–å›¾ç‰‡...")
        
        try:
            # æ–¹æ³•1: è½¬æ¢æ•´é¡µä¸ºå›¾ç‰‡
            pages = convert_from_path(self.pdf_path, dpi=300)
            for i, page in enumerate(pages, 1):
                image_file = os.path.join(self.output_dir, 'images', f'page_{i:03d}_full.png')
                page.save(image_file, 'PNG')
                self.metadata['extracted_items']['images'].append(f'page_{i:03d}_full.png')
                
            # æ–¹æ³•2: æå–åµŒå…¥çš„å›¾ç‰‡
            with pdfplumber.open(self.pdf_path) as pdf:
                for i, page in enumerate(pdf.pages, 1):
                    # æ£€æµ‹å›¾ç‰‡å¯¹è±¡
                    if hasattr(page, 'images'):
                        for j, img in enumerate(page.images):
                            try:
                                # æå–å›¾ç‰‡åŒºåŸŸ
                                bbox = (img['x0'], img['top'], img['x1'], img['bottom'])
                                cropped = page.crop(bbox)
                                
                                # è½¬æ¢ä¸ºå›¾ç‰‡
                                img_obj = cropped.to_image(resolution=300)
                                img_file = os.path.join(self.output_dir, 'images', f'page_{i:03d}_img_{j+1}.png')
                                img_obj.save(img_file)
                                self.metadata['extracted_items']['images'].append(f'page_{i:03d}_img_{j+1}.png')
                                
                            except Exception as e:
                                logger.warning(f"æå–ç¬¬{i}é¡µç¬¬{j+1}ä¸ªå›¾ç‰‡å¤±è´¥: {e}")
                                
            logger.info(f"å›¾ç‰‡æå–å®Œæˆï¼Œå…±æå– {len(self.metadata['extracted_items']['images'])} ä¸ªå›¾ç‰‡")
            
        except Exception as e:
            logger.error(f"å›¾ç‰‡æå–å¤±è´¥: {e}")
            
    def extract_tables(self):
        """æå–è¡¨æ ¼å†…å®¹"""
        logger.info("å¼€å§‹æå–è¡¨æ ¼...")
        
        try:
            # æ–¹æ³•1: ä½¿ç”¨tabula-pyæå–è¡¨æ ¼
            try:
                tables = tabula.read_pdf(self.pdf_path, pages='all', multiple_tables=True)
                for i, table in enumerate(tables):
                    if not table.empty:
                        table_file = os.path.join(self.output_dir, 'tables', f'tabula_table_{i+1:03d}.csv')
                        table.to_csv(table_file, index=False, encoding='utf-8')
                        
                        # åŒæ—¶ä¿å­˜ä¸ºExcel
                        excel_file = os.path.join(self.output_dir, 'tables', f'tabula_table_{i+1:03d}.xlsx')
                        table.to_excel(excel_file, index=False)
                        
                        self.metadata['extracted_items']['tables'].extend([
                            f'tabula_table_{i+1:03d}.csv',
                            f'tabula_table_{i+1:03d}.xlsx'
                        ])
                        
                logger.info(f"Tabulaæå–äº† {len(tables)} ä¸ªè¡¨æ ¼")
                
            except Exception as e:
                logger.warning(f"Tabulaè¡¨æ ¼æå–å¤±è´¥: {e}")
                
            # æ–¹æ³•2: ä½¿ç”¨camelotæå–è¡¨æ ¼
            try:
                tables = camelot.read_pdf(self.pdf_path, pages='all')
                for i, table in enumerate(tables):
                    table_file = os.path.join(self.output_dir, 'tables', f'camelot_table_{i+1:03d}.csv')
                    table.to_csv(table_file, encoding='utf-8')
                    
                    # ä¿å­˜è¡¨æ ¼å›¾ç‰‡
                    table_img = os.path.join(self.output_dir, 'tables', f'camelot_table_{i+1:03d}_visual.png')
                    camelot.plot(table, kind='contour').savefig(table_img)
                    plt.close()
                    
                    self.metadata['extracted_items']['tables'].extend([
                        f'camelot_table_{i+1:03d}.csv',
                        f'camelot_table_{i+1:03d}_visual.png'
                    ])
                    
                logger.info(f"Camelotæå–äº† {len(tables)} ä¸ªè¡¨æ ¼")
                
            except Exception as e:
                logger.warning(f"Camelotè¡¨æ ¼æå–å¤±è´¥: {e}")
                
            # æ–¹æ³•3: ä½¿ç”¨pdfplumberæå–è¡¨æ ¼
            try:
                with pdfplumber.open(self.pdf_path) as pdf:
                    table_count = 0
                    for i, page in enumerate(pdf.pages, 1):
                        tables = page.extract_tables()
                        for j, table in enumerate(tables):
                            if table:
                                table_count += 1
                                df = pd.DataFrame(table[1:], columns=table[0])
                                
                                table_file = os.path.join(self.output_dir, 'tables', f'pdfplumber_page_{i:03d}_table_{j+1}.csv')
                                df.to_csv(table_file, index=False, encoding='utf-8')
                                
                                excel_file = os.path.join(self.output_dir, 'tables', f'pdfplumber_page_{i:03d}_table_{j+1}.xlsx')
                                df.to_excel(excel_file, index=False)
                                
                                self.metadata['extracted_items']['tables'].extend([
                                    f'pdfplumber_page_{i:03d}_table_{j+1}.csv',
                                    f'pdfplumber_page_{i:03d}_table_{j+1}.xlsx'
                                ])
                                
                logger.info(f"PDFPlumberæå–äº† {table_count} ä¸ªè¡¨æ ¼")
                
            except Exception as e:
                logger.warning(f"PDFPlumberè¡¨æ ¼æå–å¤±è´¥: {e}")
                
        except Exception as e:
            logger.error(f"è¡¨æ ¼æå–å¤±è´¥: {e}")
            
    def detect_charts(self):
        """æ£€æµ‹å’Œæå–å›¾è¡¨"""
        logger.info("å¼€å§‹æ£€æµ‹å›¾è¡¨...")
        
        try:
            # è½¬æ¢PDFé¡µé¢ä¸ºå›¾ç‰‡è¿›è¡Œå›¾è¡¨æ£€æµ‹
            pages = convert_from_path(self.pdf_path, dpi=200)
            
            for i, page in enumerate(pages, 1):
                # è½¬æ¢ä¸ºOpenCVæ ¼å¼
                page_np = np.array(page)
                page_cv = cv2.cvtColor(page_np, cv2.COLOR_RGB2BGR)
                gray = cv2.cvtColor(page_cv, cv2.COLOR_BGR2GRAY)
                
                # æ£€æµ‹å›¾è¡¨ç‰¹å¾ï¼ˆç®€å•çš„çŸ©å½¢æ£€æµ‹ï¼‰
                edges = cv2.Canny(gray, 50, 150, apertureSize=3)
                contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                
                chart_count = 0
                for j, contour in enumerate(contours):
                    area = cv2.contourArea(contour)
                    if area > 5000:  # è¿‡æ»¤å°çš„å™ªå£°
                        x, y, w, h = cv2.boundingRect(contour)
                        aspect_ratio = w / h
                        
                        # ç®€å•çš„å›¾è¡¨åˆ¤æ–­é€»è¾‘
                        if 0.5 < aspect_ratio < 3 and w > 100 and h > 100:
                            chart_count += 1
                            
                            # æå–å›¾è¡¨åŒºåŸŸ
                            chart_region = page_cv[y:y+h, x:x+w]
                            chart_file = os.path.join(self.output_dir, 'charts', f'page_{i:03d}_chart_{chart_count}.png')
                            cv2.imwrite(chart_file, chart_region)
                            
                            self.metadata['extracted_items']['charts'].append(f'page_{i:03d}_chart_{chart_count}.png')
                            
                            # åœ¨åŸå›¾ä¸Šæ ‡è®°å›¾è¡¨ä½ç½®
                            cv2.rectangle(page_cv, (x, y), (x+w, y+h), (0, 255, 0), 2)
                            cv2.putText(page_cv, f'Chart {chart_count}', (x, y-10), 
                                      cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
                
                # ä¿å­˜æ ‡è®°äº†å›¾è¡¨çš„é¡µé¢
                if chart_count > 0:
                    marked_file = os.path.join(self.output_dir, 'charts', f'page_{i:03d}_marked.png')
                    cv2.imwrite(marked_file, page_cv)
                    self.metadata['extracted_items']['charts'].append(f'page_{i:03d}_marked.png')
                    
            logger.info(f"å›¾è¡¨æ£€æµ‹å®Œæˆï¼Œå…±æ£€æµ‹åˆ° {len([f for f in self.metadata['extracted_items']['charts'] if 'chart_' in f])} ä¸ªå›¾è¡¨")
            
        except Exception as e:
            logger.error(f"å›¾è¡¨æ£€æµ‹å¤±è´¥: {e}")
            
    def generate_analysis_report(self):
        """ç”Ÿæˆåˆ†ææŠ¥å‘Š"""
        logger.info("ç”Ÿæˆåˆ†ææŠ¥å‘Š...")
        
        try:
            report = {
                'extraction_summary': {
                    'pdf_file': self.metadata['pdf_file'],
                    'extraction_time': self.metadata['extraction_time'],
                    'total_pages': self.metadata['total_pages'],
                    'text_files_count': len(self.metadata['extracted_items']['text_files']),
                    'images_count': len(self.metadata['extracted_items']['images']),
                    'tables_count': len(self.metadata['extracted_items']['tables']),
                    'charts_count': len(self.metadata['extracted_items']['charts'])
                },
                'detailed_inventory': self.metadata['extracted_items'],
                'recommendations': []
            }
            
            # æ·»åŠ å»ºè®®
            if report['extraction_summary']['text_files_count'] > 0:
                report['recommendations'].append("æ–‡æœ¬å†…å®¹å·²æˆåŠŸæå–ï¼Œå¯ç”¨äºå†…å®¹åˆ†æå’Œæœç´¢")
                
            if report['extraction_summary']['tables_count'] > 0:
                report['recommendations'].append("è¡¨æ ¼æ•°æ®å·²æå–ä¸ºCSVå’ŒExcelæ ¼å¼ï¼Œå¯è¿›è¡Œæ•°æ®åˆ†æ")
                
            if report['extraction_summary']['images_count'] > 0:
                report['recommendations'].append("å›¾ç‰‡å·²æå–ä¸ºPNGæ ¼å¼ï¼Œå¯ç”¨äºè§†è§‰åˆ†æ")
                
            if report['extraction_summary']['charts_count'] > 0:
                report['recommendations'].append("å›¾è¡¨å·²æ£€æµ‹å¹¶æå–ï¼Œå¯ç”¨äºæ•°æ®å¯è§†åŒ–åˆ†æ")
            
            # ä¿å­˜æŠ¥å‘Š
            report_file = os.path.join(self.output_dir, 'reports', 'extraction_report.json')
            with open(report_file, 'w', encoding='utf-8') as f:
                json.dump(report, f, ensure_ascii=False, indent=2)
                
            # ç”ŸæˆHTMLæŠ¥å‘Š
            html_report = self.generate_html_report(report)
            html_file = os.path.join(self.output_dir, 'reports', 'extraction_report.html')
            with open(html_file, 'w', encoding='utf-8') as f:
                f.write(html_report)
                
            logger.info("åˆ†ææŠ¥å‘Šç”Ÿæˆå®Œæˆ")
            
        except Exception as e:
            logger.error(f"ç”Ÿæˆåˆ†ææŠ¥å‘Šå¤±è´¥: {e}")
            
    def generate_html_report(self, report):
        """ç”ŸæˆHTMLæ ¼å¼çš„æŠ¥å‘Š"""
        html = f"""
        <!DOCTYPE html>
        <html lang="zh-CN">
        <head>
            <meta charset="UTF-8">
            <meta name="viewport" content="width=device-width, initial-scale=1.0">
            <title>PDFå†…å®¹æå–æŠ¥å‘Š</title>
            <style>
                body {{ font-family: 'Microsoft YaHei', sans-serif; margin: 20px; }}
                .header {{ background: #f5f5f5; padding: 20px; border-radius: 8px; }}
                .section {{ margin: 20px 0; padding: 15px; border: 1px solid #ddd; border-radius: 5px; }}
                .summary-grid {{ display: grid; grid-template-columns: repeat(auto-fit, minmax(200px, 1fr)); gap: 15px; }}
                .summary-card {{ background: #e8f4fd; padding: 15px; border-radius: 5px; text-align: center; }}
                .file-list {{ max-height: 300px; overflow-y: auto; }}
                .file-item {{ padding: 5px; border-bottom: 1px solid #eee; }}
                .recommendation {{ background: #f0f8f0; padding: 10px; margin: 5px 0; border-left: 4px solid #4CAF50; }}
            </style>
        </head>
        <body>
            <div class="header">
                <h1>PDFå†…å®¹æå–æŠ¥å‘Š</h1>
                <p><strong>æ–‡ä»¶:</strong> {report['extraction_summary']['pdf_file']}</p>
                <p><strong>æå–æ—¶é—´:</strong> {report['extraction_summary']['extraction_time']}</p>
            </div>
            
            <div class="section">
                <h2>æå–æ¦‚è¦</h2>
                <div class="summary-grid">
                    <div class="summary-card">
                        <h3>{report['extraction_summary']['total_pages']}</h3>
                        <p>æ€»é¡µæ•°</p>
                    </div>
                    <div class="summary-card">
                        <h3>{report['extraction_summary']['text_files_count']}</h3>
                        <p>æ–‡æœ¬æ–‡ä»¶</p>
                    </div>
                    <div class="summary-card">
                        <h3>{report['extraction_summary']['images_count']}</h3>
                        <p>å›¾ç‰‡æ–‡ä»¶</p>
                    </div>
                    <div class="summary-card">
                        <h3>{report['extraction_summary']['tables_count']}</h3>
                        <p>è¡¨æ ¼æ–‡ä»¶</p>
                    </div>
                    <div class="summary-card">
                        <h3>{report['extraction_summary']['charts_count']}</h3>
                        <p>å›¾è¡¨æ–‡ä»¶</p>
                    </div>
                </div>
            </div>
            
            <div class="section">
                <h2>æ–‡ä»¶æ¸…å•</h2>
                <h3>æ–‡æœ¬æ–‡ä»¶</h3>
                <div class="file-list">
                    {''.join([f'<div class="file-item">ğŸ“„ {f}</div>' for f in report['detailed_inventory']['text_files']])}
                </div>
                
                <h3>å›¾ç‰‡æ–‡ä»¶</h3>
                <div class="file-list">
                    {''.join([f'<div class="file-item">ğŸ–¼ï¸ {f}</div>' for f in report['detailed_inventory']['images']])}
                </div>
                
                <h3>è¡¨æ ¼æ–‡ä»¶</h3>
                <div class="file-list">
                    {''.join([f'<div class="file-item">ğŸ“Š {f}</div>' for f in report['detailed_inventory']['tables']])}
                </div>
                
                <h3>å›¾è¡¨æ–‡ä»¶</h3>
                <div class="file-list">
                    {''.join([f'<div class="file-item">ğŸ“ˆ {f}</div>' for f in report['detailed_inventory']['charts']])}
                </div>
            </div>
            
            <div class="section">
                <h2>ä½¿ç”¨å»ºè®®</h2>
                {''.join([f'<div class="recommendation">ğŸ’¡ {rec}</div>' for rec in report['recommendations']])}
            </div>
        </body>
        </html>
        """
        return html
        
    def run_extraction(self, extract_text=True, extract_images=True, extract_tables=True, detect_charts=True):
        """è¿è¡Œå®Œæ•´çš„æå–æµç¨‹"""
        logger.info(f"å¼€å§‹å¤„ç†PDFæ–‡ä»¶: {self.pdf_path}")
        
        # æå–å…ƒæ•°æ®
        self.extract_metadata()
        
        # æ ¹æ®å‚æ•°é€‰æ‹©æå–å†…å®¹
        if extract_text:
            self.extract_text_content()
            
        if extract_images:
            self.extract_images()
            
        if extract_tables:
            self.extract_tables()
            
        if detect_charts:
            self.detect_charts()
            
        # ç”ŸæˆæŠ¥å‘Š
        self.generate_analysis_report()
        
        # ä¿å­˜å…ƒæ•°æ®
        metadata_file = os.path.join(self.output_dir, 'metadata', 'extraction_metadata.json')
        with open(metadata_file, 'w', encoding='utf-8') as f:
            json.dump(self.metadata, f, ensure_ascii=False, indent=2)
            
        logger.info("PDFå†…å®¹æå–å®Œæˆ!")
        return self.metadata

def main():
    import argparse
    
    parser = argparse.ArgumentParser(description='ç»¼åˆPDFå†…å®¹æå–å·¥å…·')
    parser.add_argument('pdf_path', help='PDFæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--output-dir', default='pdf_extracted_content', help='è¾“å‡ºç›®å½•')
    parser.add_argument('--no-text', action='store_true', help='ä¸æå–æ–‡æœ¬')
    parser.add_argument('--no-images', action='store_true', help='ä¸æå–å›¾ç‰‡')
    parser.add_argument('--no-tables', action='store_true', help='ä¸æå–è¡¨æ ¼')
    parser.add_argument('--no-charts', action='store_true', help='ä¸æ£€æµ‹å›¾è¡¨')
    
    args = parser.parse_args()
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(args.output_dir, exist_ok=True)
    for subdir in ['text', 'images', 'tables', 'charts', 'metadata', 'reports']:
        os.makedirs(os.path.join(args.output_dir, subdir), exist_ok=True)
    
    # åˆ›å»ºæå–å™¨å¹¶è¿è¡Œ
    extractor = ComprehensivePDFExtractor(args.pdf_path, args.output_dir)
    result = extractor.run_extraction(
        extract_text=not args.no_text,
        extract_images=not args.no_images,
        extract_tables=not args.no_tables,
        detect_charts=not args.no_charts
    )
    
    print(f"\næå–å®Œæˆ! ç»“æœä¿å­˜åœ¨: {args.output_dir}")
    print(f"æ€»é¡µæ•°: {result['total_pages']}")
    print(f"æå–çš„æ–‡ä»¶æ•°é‡:")
    print(f"  - æ–‡æœ¬æ–‡ä»¶: {len(result['extracted_items']['text_files'])}")
    print(f"  - å›¾ç‰‡æ–‡ä»¶: {len(result['extracted_items']['images'])}")
    print(f"  - è¡¨æ ¼æ–‡ä»¶: {len(result['extracted_items']['tables'])}")
    print(f"  - å›¾è¡¨æ–‡ä»¶: {len(result['extracted_items']['charts'])}")

if __name__ == "__main__":
    main()
"@

    Set-Content -Path $ScriptPath -Value $pythonScript -Encoding UTF8
}

# ä¸»å‡½æ•°
function Main {
    Write-Host "=== ç»¼åˆPDFå†…å®¹æå–å·¥å…· ===" -ForegroundColor Cyan
    Write-Host "åŠŸèƒ½ï¼šæå–PDFä¸­çš„æ–‡å­—ã€å›¾è¡¨ã€å›¾ç‰‡ç­‰æ‰€æœ‰å†…å®¹" -ForegroundColor Cyan
    Write-Host ""
    
    # æ£€æŸ¥PDFæ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if (!(Test-Path $PdfPath)) {
        Write-Error "PDFæ–‡ä»¶ä¸å­˜åœ¨: $PdfPath"
        return
    }
    
    # è·å–PDFæ–‡ä»¶ä¿¡æ¯
    $pdfFile = Get-Item $PdfPath
    Write-Host "å¤„ç†æ–‡ä»¶: $($pdfFile.Name)" -ForegroundColor Green
    Write-Host "æ–‡ä»¶å¤§å°: $([math]::Round($pdfFile.Length / 1MB, 2)) MB" -ForegroundColor Green
    Write-Host ""
    
    # æ£€æŸ¥Pythonç¯å¢ƒ
    Test-PythonLibraries
    Write-Host ""
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    $timestamp = Get-Date -Format "yyyyMMdd_HHmmss"
    $outputPath = "$OutputDir`_$timestamp"
    New-OutputDirectories -BaseDir $outputPath
    Write-Host ""
    
    # ç”ŸæˆPythonæå–è„šæœ¬
    $pythonScriptPath = Join-Path $outputPath "pdf_extractor.py"
    New-PythonExtractorScript -ScriptPath $pythonScriptPath
    Write-Host "ç”ŸæˆPythonæå–è„šæœ¬: $pythonScriptPath" -ForegroundColor Green
    Write-Host ""
    
    # æ„å»ºPythonå‘½ä»¤å‚æ•°
    $pythonArgs = @(
        $pythonScriptPath,
        "`"$PdfPath`"",
        "--output-dir", "`"$outputPath`""
    )
    
    if (!$ExtractText) { $pythonArgs += "--no-text" }
    if (!$ExtractImages) { $pythonArgs += "--no-images" }
    if (!$ExtractTables) { $pythonArgs += "--no-tables" }
    
    # æ‰§è¡ŒPythonæå–è„šæœ¬
    Write-Host "å¼€å§‹æå–PDFå†…å®¹..." -ForegroundColor Yellow
    Write-Host "å‘½ä»¤: python $($pythonArgs -join ' ')" -ForegroundColor Gray
    Write-Host ""
    
    try {
        $result = & python @pythonArgs
        Write-Host $result -ForegroundColor Green
        
        # æ˜¾ç¤ºè¾“å‡ºç›®å½•ç»“æ„
        Write-Host "`n=== è¾“å‡ºç›®å½•ç»“æ„ ===" -ForegroundColor Cyan
        Get-ChildItem $outputPath -Recurse | ForEach-Object {
            $relativePath = $_.FullName.Replace($outputPath, "").TrimStart('\')
            if ($_.PSIsContainer) {
                Write-Host "ğŸ“ $relativePath" -ForegroundColor Yellow
            } else {
                $size = if ($_.Length -gt 1MB) { "$([math]::Round($_.Length / 1MB, 2)) MB" } 
                        elseif ($_.Length -gt 1KB) { "$([math]::Round($_.Length / 1KB, 2)) KB" }
                        else { "$($_.Length) B" }
                Write-Host "ğŸ“„ $relativePath ($size)" -ForegroundColor White
            }
        }
        
        # ç”Ÿæˆä½¿ç”¨æŒ‡å—
        $guideContent = @"
# PDFå†…å®¹æå–ç»“æœä½¿ç”¨æŒ‡å—

## ç›®å½•ç»“æ„è¯´æ˜
- **text/**: æå–çš„æ–‡æœ¬å†…å®¹
  - full_text.txt: å®Œæ•´æ–‡æœ¬å†…å®¹
  - structured_text.json: ç»“æ„åŒ–æ–‡æœ¬æ•°æ®
  - page_xxx.txt: å„é¡µé¢æ–‡æœ¬
  - detailed_text.txt: è¯¦ç»†æ–‡æœ¬å†…å®¹

- **images/**: æå–çš„å›¾ç‰‡
  - page_xxx_full.png: å®Œæ•´é¡µé¢å›¾ç‰‡
  - page_xxx_img_x.png: é¡µé¢ä¸­çš„åµŒå…¥å›¾ç‰‡

- **tables/**: æå–çš„è¡¨æ ¼
  - *.csv: CSVæ ¼å¼è¡¨æ ¼æ•°æ®
  - *.xlsx: Excelæ ¼å¼è¡¨æ ¼æ•°æ®
  - *_visual.png: è¡¨æ ¼å¯è§†åŒ–å›¾ç‰‡

- **charts/**: æ£€æµ‹çš„å›¾è¡¨
  - page_xxx_chart_x.png: æ£€æµ‹åˆ°çš„å›¾è¡¨
  - page_xxx_marked.png: æ ‡è®°äº†å›¾è¡¨ä½ç½®çš„é¡µé¢

- **metadata/**: å…ƒæ•°æ®ä¿¡æ¯
  - extraction_metadata.json: æå–è¿‡ç¨‹çš„å…ƒæ•°æ®

- **reports/**: åˆ†ææŠ¥å‘Š
  - extraction_report.json: JSONæ ¼å¼æŠ¥å‘Š
  - extraction_report.html: HTMLæ ¼å¼æŠ¥å‘Š

## ä½¿ç”¨å»ºè®®
1. æŸ¥çœ‹reports/extraction_report.htmlè·å–å®Œæ•´çš„æå–æ¦‚è§ˆ
2. ä½¿ç”¨text/full_text.txtè¿›è¡Œå…¨æ–‡æœç´¢å’Œåˆ†æ
3. ä½¿ç”¨tables/ç›®å½•ä¸­çš„CSV/Excelæ–‡ä»¶è¿›è¡Œæ•°æ®åˆ†æ
4. ä½¿ç”¨images/ç›®å½•ä¸­çš„å›¾ç‰‡è¿›è¡Œè§†è§‰åˆ†æ
5. ä½¿ç”¨charts/ç›®å½•ä¸­çš„å›¾è¡¨è¿›è¡Œæ•°æ®å¯è§†åŒ–åˆ†æ

## åç»­å¤„ç†å»ºè®®
- å¯ä»¥ä½¿ç”¨æ–‡æœ¬åˆ†æå·¥å…·å¯¹æå–çš„æ–‡æœ¬è¿›è¡Œå…³é”®è¯æå–ã€æƒ…æ„Ÿåˆ†æç­‰
- å¯ä»¥ä½¿ç”¨æ•°æ®åˆ†æå·¥å…·å¯¹è¡¨æ ¼æ•°æ®è¿›è¡Œç»Ÿè®¡åˆ†æ
- å¯ä»¥ä½¿ç”¨å›¾åƒè¯†åˆ«å·¥å…·å¯¹å›¾ç‰‡è¿›è¡Œè¿›ä¸€æ­¥åˆ†æ
- å¯ä»¥å°†æå–çš„å†…å®¹æ•´åˆåˆ°çŸ¥è¯†åº“æˆ–æ–‡æ¡£ç®¡ç†ç³»ç»Ÿä¸­

ç”Ÿæˆæ—¶é—´: $(Get-Date)
"@
        
        $guideFile = Join-Path $outputPath "ä½¿ç”¨æŒ‡å—.md"
        Set-Content -Path $guideFile -Value $guideContent -Encoding UTF8
        
        Write-Host "`nâœ… æå–å®Œæˆ!" -ForegroundColor Green
        Write-Host "ğŸ“ è¾“å‡ºç›®å½•: $outputPath" -ForegroundColor Green
        Write-Host "ğŸ“– ä½¿ç”¨æŒ‡å—: $guideFile" -ForegroundColor Green
        Write-Host "ğŸŒ HTMLæŠ¥å‘Š: $(Join-Path $outputPath 'reports\extraction_report.html')" -ForegroundColor Green
        
        if ($GenerateReport) {
            # å°è¯•æ‰“å¼€HTMLæŠ¥å‘Š
            $htmlReport = Join-Path $outputPath "reports\extraction_report.html"
            if (Test-Path $htmlReport) {
                Write-Host "`næ˜¯å¦æ‰“å¼€HTMLæŠ¥å‘Š? (Y/N): " -NoNewline -ForegroundColor Yellow
                $response = Read-Host
                if ($response -eq 'Y' -or $response -eq 'y') {
                    Start-Process $htmlReport
                }
            }
        }
        
    } catch {
        Write-Error "æ‰§è¡ŒPythonè„šæœ¬æ—¶å‡ºé”™: $($_.Exception.Message)"
        Write-Host "è¯·æ£€æŸ¥Pythonç¯å¢ƒå’Œä¾èµ–åº“æ˜¯å¦æ­£ç¡®å®‰è£…" -ForegroundColor Red
    }
}

# æ‰§è¡Œä¸»å‡½æ•°
Main 