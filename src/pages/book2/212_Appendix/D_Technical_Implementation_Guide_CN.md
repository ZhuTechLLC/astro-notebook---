---
title: "é™„å½•Dï¼šæŠ€æœ¯å®ç°æŒ‡å—"
description: "è¯¦ç»†çš„æŠ€æœ¯å®ç°æŒ‡å—ï¼ŒåŒ…æ‹¬ç¼–ç¨‹ä»£ç ç¤ºä¾‹ã€æ¨¡å‹æ„å»ºæ­¥éª¤ã€ç³»ç»Ÿæ­å»ºæ•™ç¨‹ç­‰æŠ€æœ¯èµ„æ–™"
lang: "zh-CN"
alt: "æŠ€æœ¯å®ç°æŒ‡å—"
layout: "/src/layouts/HandbookLayout.astro"
updateDate: "2025-01-03"
---

# é™„å½•Dï¼šæŠ€æœ¯å®ç°æŒ‡å—

**æ ¸å¿ƒæ‘˜è¦ï¼š**
> 
> æœ¬é™„å½•æä¾›å®è§‚ç»æµåˆ†æçš„æŠ€æœ¯å®ç°æŒ‡å—ï¼Œæ¶µç›–æ•°æ®è·å–ã€æ¨¡å‹æ„å»ºã€ç³»ç»Ÿæ­å»ºç­‰æŠ€æœ¯ç»†èŠ‚ã€‚é€šè¿‡è¯¦ç»†çš„ä»£ç ç¤ºä¾‹å’Œæ­¥éª¤æŒ‡å¯¼ï¼Œå¸®åŠ©æŠ•èµ„è€…å»ºç«‹è‡ªåŠ¨åŒ–çš„å®è§‚åˆ†æç³»ç»Ÿï¼Œæå‡åˆ†ææ•ˆç‡å’ŒæŠ€æœ¯èƒ½åŠ›ã€‚

## ğŸ“– æŠ€æœ¯æ¶æ„æ¦‚è§ˆ

<div class="chapter-overview">
<div class="overview-grid">
<div class="overview-item">
<h4>ğŸ“Š æ•°æ®è·å–ç³»ç»Ÿ</h4>
<p>è‡ªåŠ¨åŒ–æ•°æ®æŠ“å–ã€æ¸…æ´—å’Œå­˜å‚¨çš„æŠ€æœ¯å®ç°</p>
</div>
<div class="overview-item">
<h4>ğŸ”§ åˆ†ææ¨¡å‹æ„å»º</h4>
<p>ç»æµé¢„æµ‹æ¨¡å‹ã€é£é™©è¯„ä¼°æ¨¡å‹çš„ä»£ç å®ç°</p>
</div>
<div class="overview-item">
<h4>ğŸ“ˆ å¯è§†åŒ–ç³»ç»Ÿ</h4>
<p>åŠ¨æ€å›¾è¡¨ã€ä»ªè¡¨æ¿çš„å¼€å‘å’Œéƒ¨ç½²</p>
</div>
<div class="overview-item">
<h4>âš¡ å®æ—¶ç›‘æ§ç³»ç»Ÿ</h4>
<p>å®æ—¶æ•°æ®å¤„ç†å’Œé¢„è­¦ç³»ç»Ÿçš„æŠ€æœ¯æ¶æ„</p>
</div>
<div class="overview-item">
<h4>ğŸŒ Webåº”ç”¨å¼€å‘</h4>
<p>åŸºäºWebçš„å®è§‚åˆ†æå¹³å°æ­å»º</p>
</div>
<div class="overview-item">
<h4>ğŸ› ï¸ ç³»ç»Ÿéƒ¨ç½²è¿ç»´</h4>
<p>äº‘ç«¯éƒ¨ç½²ã€è‡ªåŠ¨åŒ–è¿ç»´çš„æœ€ä½³å®è·µ</p>
</div>
</div>
</div>

## ğŸ“Š æ•°æ®è·å–ç³»ç»Ÿ

### ğŸ Pythonæ•°æ®è·å–æ¡†æ¶

**ç¯å¢ƒé…ç½®**
```python
# å®‰è£…å¿…è¦çš„åº“
pip install pandas numpy requests fredapi yfinance alpha_vantage

# å¯¼å…¥æ ¸å¿ƒåº“
import pandas as pd
import numpy as np
import requests
from fredapi import Fred
import yfinance as yf
from alpha_vantage.timeseries import TimeSeries
```

**å¤šæ•°æ®æºæ•´åˆç±»**
```python
class MacroDataCollector:
    def __init__(self):
        self.fred = Fred(api_key='your_fred_api_key')
        self.alpha_vantage = TimeSeries(key='your_alpha_vantage_key')
        
    def get_economic_indicators(self, indicators, start_date='2020-01-01'):
        """è·å–ç»æµæŒ‡æ ‡æ•°æ®"""
        data = {}
        for indicator in indicators:
            try:
                series = self.fred.get_series(indicator, start=start_date)
                data[indicator] = series
            except Exception as e:
                print(f"è·å–{indicator}æ•°æ®å¤±è´¥: {e}")
        return pd.DataFrame(data)
    
    def get_market_data(self, symbols, start_date='2020-01-01'):
        """è·å–å¸‚åœºæ•°æ®"""
        data = {}
        for symbol in symbols:
            try:
                ticker = yf.Ticker(symbol)
                hist = ticker.history(start=start_date)
                data[symbol] = hist['Close']
            except Exception as e:
                print(f"è·å–{symbol}æ•°æ®å¤±è´¥: {e}")
        return pd.DataFrame(data)
```

### ğŸ“¡ APIæ•°æ®è·å–ç¤ºä¾‹

**FREDæ•°æ®è·å–**
```python
# ä¸»è¦å®è§‚æŒ‡æ ‡
indicators = {
    'GDP': 'GDP',
    'CPI': 'CPIAUCSL',
    'UNEMPLOYMENT': 'UNRATE',
    'FEDERAL_FUNDS_RATE': 'FEDFUNDS',
    'YIELD_10Y': 'GS10'
}

collector = MacroDataCollector()
macro_data = collector.get_economic_indicators(list(indicators.values()))
macro_data.columns = list(indicators.keys())
```

**å®æ—¶æ•°æ®æ›´æ–°ç³»ç»Ÿ**
```python
import schedule
import time
from datetime import datetime

class DataUpdateScheduler:
    def __init__(self, data_collector):
        self.collector = data_collector
        
    def update_daily_data(self):
        """æ¯æ—¥æ•°æ®æ›´æ–°"""
        try:
            # è·å–æœ€æ–°æ•°æ®
            new_data = self.collector.get_economic_indicators(
                ['GDP', 'CPIAUCSL', 'UNRATE']
            )
            
            # ä¿å­˜åˆ°æ•°æ®åº“
            self.save_to_database(new_data)
            
            print(f"æ•°æ®æ›´æ–°å®Œæˆ: {datetime.now()}")
            
        except Exception as e:
            print(f"æ•°æ®æ›´æ–°å¤±è´¥: {e}")
    
    def save_to_database(self, data):
        """ä¿å­˜æ•°æ®åˆ°æ•°æ®åº“"""
        # è¿™é‡Œä½¿ç”¨SQLiteä½œä¸ºç¤ºä¾‹
        import sqlite3
        conn = sqlite3.connect('macro_data.db')
        data.to_sql('economic_indicators', conn, if_exists='append')
        conn.close()

# è®¾ç½®å®šæ—¶ä»»åŠ¡
scheduler = DataUpdateScheduler(collector)
schedule.every().day.at("09:00").do(scheduler.update_daily_data)
```

## ğŸ”§ åˆ†ææ¨¡å‹æ„å»º

### ğŸ“ˆ ç»æµé¢„æµ‹æ¨¡å‹

**GDPå¢é•¿é¢„æµ‹æ¨¡å‹**
```python
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

class GDPForecastModel:
    def __init__(self):
        self.model = RandomForestRegressor(n_estimators=100, random_state=42)
        self.features = []
        
    def prepare_features(self, data):
        """å‡†å¤‡ç‰¹å¾æ•°æ®"""
        # è®¡ç®—åŒæ¯”å¢é•¿ç‡
        growth_rates = data.pct_change(periods=4) * 100
        
        # è®¡ç®—ç§»åŠ¨å¹³å‡
        ma_3 = data.rolling(window=3).mean()
        ma_12 = data.rolling(window=12).mean()
        
        # è®¡ç®—æŠ€æœ¯æŒ‡æ ‡
        features = pd.DataFrame({
            'cpi_growth': growth_rates['CPI'],
            'unemployment_rate': data['UNEMPLOYMENT'],
            'fed_funds_rate': data['FEDERAL_FUNDS_RATE'],
            'yield_10y': data['YIELD_10Y'],
            'cpi_ma3': ma_3['CPI'],
            'unemployment_ma12': ma_12['UNEMPLOYMENT']
        })
        
        return features.dropna()
    
    def train_model(self, X, y):
        """è®­ç»ƒæ¨¡å‹"""
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42
        )
        
        self.model.fit(X_train, y_train)
        
        # æ¨¡å‹è¯„ä¼°
        y_pred = self.model.predict(X_test)
        mse = mean_squared_error(y_test, y_pred)
        r2 = r2_score(y_test, y_pred)
        
        print(f"æ¨¡å‹è¯„ä¼° - MSE: {mse:.4f}, RÂ²: {r2:.4f}")
        
        return {
            'mse': mse,
            'r2': r2,
            'feature_importance': dict(zip(X.columns, self.model.feature_importances_))
        }
    
    def predict(self, X):
        """é¢„æµ‹GDPå¢é•¿"""
        return self.model.predict(X)
```

### ğŸ“Š é£é™©è¯„ä¼°æ¨¡å‹

**ç³»ç»Ÿæ€§é£é™©è¯„ä¼°**
```python
import numpy as np
from scipy import stats

class SystemicRiskModel:
    def __init__(self):
        self.risk_indicators = {}
        
    def calculate_financial_stress_index(self, data):
        """è®¡ç®—é‡‘èå‹åŠ›æŒ‡æ•°"""
        # æ ‡å‡†åŒ–å„ä¸ªæŒ‡æ ‡
        indicators = {}
        
        # VIXæŒ‡æ•°ï¼ˆææ…ŒæŒ‡æ•°ï¼‰
        vix_zscore = (data['VIX'] - data['VIX'].mean()) / data['VIX'].std()
        indicators['vix_stress'] = vix_zscore
        
        # åˆ©ç‡æœŸé™ç»“æ„
        yield_curve = data['YIELD_10Y'] - data['YIELD_2Y']
        curve_zscore = (yield_curve - yield_curve.mean()) / yield_curve.std()
        indicators['yield_curve_stress'] = -curve_zscore  # å€’æŒ‚æ—¶å‹åŠ›å¢åŠ 
        
        # ä¿¡ç”¨åˆ©å·®
        credit_spread = data['CREDIT_SPREAD']
        spread_zscore = (credit_spread - credit_spread.mean()) / credit_spread.std()
        indicators['credit_stress'] = spread_zscore
        
        # æ±‡ç‡æ³¢åŠ¨
        dollar_volatility = data['DXY'].pct_change().rolling(30).std()
        vol_zscore = (dollar_volatility - dollar_volatility.mean()) / dollar_volatility.std()
        indicators['currency_stress'] = vol_zscore
        
        # ç»¼åˆé‡‘èå‹åŠ›æŒ‡æ•°
        weights = {'vix_stress': 0.3, 'yield_curve_stress': 0.2, 
                  'credit_stress': 0.3, 'currency_stress': 0.2}
        
        stress_index = sum(indicators[key] * weights[key] 
                          for key in weights.keys())
        
        return stress_index
    
    def calculate_risk_probabilities(self, stress_index):
        """è®¡ç®—é£é™©æ¦‚ç‡"""
        # åŸºäºå†å²åˆ†å¸ƒè®¡ç®—æ¦‚ç‡
        percentiles = {
            'low_risk': 25,
            'medium_risk': 75,
            'high_risk': 95
        }
        
        current_stress = stress_index.iloc[-1]
        
        probabilities = {}
        for risk_level, threshold in percentiles.items():
            prob = stats.percentileofscore(stress_index.dropna(), current_stress)
            probabilities[risk_level] = prob / 100
            
        return probabilities
```

## ğŸ“ˆ å¯è§†åŒ–ç³»ç»Ÿ

### ğŸ¨ åŠ¨æ€ä»ªè¡¨æ¿

**Plotlyä»ªè¡¨æ¿**
```python
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import plotly.express as px

class MacroDashboard:
    def __init__(self, data):
        self.data = data
        
    def create_economic_overview(self):
        """åˆ›å»ºç»æµæ¦‚è§ˆå›¾è¡¨"""
        fig = make_subplots(
            rows=2, cols=2,
            subplot_titles=('GDPå¢é•¿ç‡', 'é€šèƒ€ç‡', 'å¤±ä¸šç‡', 'è”é‚¦åŸºé‡‘åˆ©ç‡'),
            specs=[[{"secondary_y": False}, {"secondary_y": False}],
                   [{"secondary_y": False}, {"secondary_y": False}]]
        )
        
        # GDPå¢é•¿ç‡
        fig.add_trace(
            go.Scatter(x=self.data.index, y=self.data['GDP_GROWTH'],
                      mode='lines', name='GDPå¢é•¿ç‡', line=dict(color='blue')),
            row=1, col=1
        )
        
        # é€šèƒ€ç‡
        fig.add_trace(
            go.Scatter(x=self.data.index, y=self.data['CPI_GROWTH'],
                      mode='lines', name='CPIå¢é•¿ç‡', line=dict(color='red')),
            row=1, col=2
        )
        
        # å¤±ä¸šç‡
        fig.add_trace(
            go.Scatter(x=self.data.index, y=self.data['UNEMPLOYMENT'],
                      mode='lines', name='å¤±ä¸šç‡', line=dict(color='green')),
            row=2, col=1
        )
        
        # è”é‚¦åŸºé‡‘åˆ©ç‡
        fig.add_trace(
            go.Scatter(x=self.data.index, y=self.data['FEDERAL_FUNDS_RATE'],
                      mode='lines', name='è”é‚¦åŸºé‡‘åˆ©ç‡', line=dict(color='purple')),
            row=2, col=2
        )
        
        fig.update_layout(
            title="å®è§‚ç»æµæŒ‡æ ‡æ¦‚è§ˆ",
            showlegend=False,
            height=600
        )
        
        return fig
    
    def create_risk_gauge(self, risk_score):
        """åˆ›å»ºé£é™©ä»ªè¡¨ç›˜"""
        fig = go.Figure(go.Indicator(
            mode="gauge+number+delta",
            value=risk_score,
            domain={'x': [0, 1], 'y': [0, 1]},
            title={'text': "ç³»ç»Ÿæ€§é£é™©æŒ‡æ•°"},
            delta={'reference': 0},
            gauge={
                'axis': {'range': [None, 100]},
                'bar': {'color': "darkblue"},
                'steps': [
                    {'range': [0, 25], 'color': "lightgray"},
                    {'range': [25, 50], 'color': "yellow"},
                    {'range': [50, 75], 'color': "orange"},
                    {'range': [75, 100], 'color': "red"}
                ],
                'threshold': {
                    'line': {'color': "red", 'width': 4},
                    'thickness': 0.75,
                    'value': 90
                }
            }
        ))
        
        return fig
```

### ğŸ“Š å®æ—¶å›¾è¡¨æ›´æ–°

**WebSocketå®æ—¶æ•°æ®æµ**
```python
import asyncio
import websockets
import json
from datetime import datetime

class RealTimeDataStream:
    def __init__(self):
        self.clients = set()
        self.data_collector = MacroDataCollector()
        
    async def register_client(self, websocket, path):
        """æ³¨å†Œå®¢æˆ·ç«¯"""
        self.clients.add(websocket)
        try:
            await websocket.wait_closed()
        finally:
            self.clients.remove(websocket)
    
    async def broadcast_data(self, data):
        """å¹¿æ’­æ•°æ®åˆ°æ‰€æœ‰å®¢æˆ·ç«¯"""
        if self.clients:
            message = json.dumps({
                'timestamp': datetime.now().isoformat(),
                'data': data
            })
            await asyncio.gather(
                *[client.send(message) for client in self.clients],
                return_exceptions=True
            )
    
    async def data_update_loop(self):
        """æ•°æ®æ›´æ–°å¾ªç¯"""
        while True:
            try:
                # è·å–æœ€æ–°æ•°æ®
                latest_data = self.get_latest_market_data()
                
                # å¹¿æ’­ç»™æ‰€æœ‰å®¢æˆ·ç«¯
                await self.broadcast_data(latest_data)
                
                # ç­‰å¾…1åˆ†é’Ÿ
                await asyncio.sleep(60)
                
            except Exception as e:
                print(f"æ•°æ®æ›´æ–°é”™è¯¯: {e}")
                await asyncio.sleep(60)
    
    def get_latest_market_data(self):
        """è·å–æœ€æ–°å¸‚åœºæ•°æ®"""
        # è¿™é‡Œå®ç°è·å–æœ€æ–°å¸‚åœºæ•°æ®çš„é€»è¾‘
        return {
            'sp500': 4150.5,
            'vix': 18.2,
            'dxy': 103.1,
            'yield_10y': 4.2
        }
```

## âš¡ å®æ—¶ç›‘æ§ç³»ç»Ÿ

### ğŸš¨ é¢„è­¦ç³»ç»Ÿ

**å¼‚å¸¸æ£€æµ‹ç®—æ³•**
```python
from sklearn.ensemble import IsolationForest
import numpy as np

class AnomalyDetectionSystem:
    def __init__(self):
        self.models = {}
        self.thresholds = {}
        
    def train_anomaly_detector(self, data, indicator_name):
        """è®­ç»ƒå¼‚å¸¸æ£€æµ‹æ¨¡å‹"""
        # ä½¿ç”¨å­¤ç«‹æ£®æ—ç®—æ³•
        model = IsolationForest(
            contamination=0.1,  # å‡è®¾10%çš„æ•°æ®æ˜¯å¼‚å¸¸
            random_state=42
        )
        
        # å‡†å¤‡ç‰¹å¾
        features = self.prepare_features(data)
        model.fit(features)
        
        self.models[indicator_name] = model
        
        # è®¡ç®—å¼‚å¸¸åˆ†æ•°é˜ˆå€¼
        anomaly_scores = model.decision_function(features)
        threshold = np.percentile(anomaly_scores, 10)  # 10%åˆ†ä½æ•°ä½œä¸ºé˜ˆå€¼
        self.thresholds[indicator_name] = threshold
        
        return model
    
    def detect_anomalies(self, new_data, indicator_name):
        """æ£€æµ‹å¼‚å¸¸"""
        if indicator_name not in self.models:
            raise ValueError(f"æœªæ‰¾åˆ°{indicator_name}çš„å¼‚å¸¸æ£€æµ‹æ¨¡å‹")
        
        model = self.models[indicator_name]
        features = self.prepare_features(new_data)
        
        # é¢„æµ‹å¼‚å¸¸
        anomaly_labels = model.predict(features)
        anomaly_scores = model.decision_function(features)
        
        # è¯†åˆ«å¼‚å¸¸ç‚¹
        anomalies = []
        for i, (label, score) in enumerate(zip(anomaly_labels, anomaly_scores)):
            if label == -1:  # å¼‚å¸¸ç‚¹
                anomalies.append({
                    'index': i,
                    'timestamp': new_data.index[i],
                    'value': new_data.iloc[i],
                    'anomaly_score': score,
                    'severity': self.calculate_severity(score)
                })
        
        return anomalies
    
    def calculate_severity(self, score):
        """è®¡ç®—å¼‚å¸¸ä¸¥é‡ç¨‹åº¦"""
        if score < -0.5:
            return 'HIGH'
        elif score < -0.2:
            return 'MEDIUM'
        else:
            return 'LOW'
```

### ğŸ“§ è‡ªåŠ¨åŒ–æŠ¥å‘Šç³»ç»Ÿ

**é‚®ä»¶æŠ¥å‘Šç”Ÿæˆ**
```python
import smtplib
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
from email.mime.base import MIMEBase
from email import encoders
import os

class AutoReportSystem:
    def __init__(self, smtp_server, smtp_port, email, password):
        self.smtp_server = smtp_server
        self.smtp_port = smtp_port
        self.email = email
        self.password = password
        
    def generate_weekly_report(self, data):
        """ç”Ÿæˆå‘¨æŠ¥"""
        report = {
            'summary': self.generate_summary(data),
            'key_indicators': self.analyze_key_indicators(data),
            'market_outlook': self.generate_outlook(data),
            'risk_assessment': self.assess_risks(data)
        }
        
        return report
    
    def generate_summary(self, data):
        """ç”Ÿæˆæ‘˜è¦"""
        latest_data = data.iloc[-1]
        prev_week_data = data.iloc[-5]
        
        summary = f"""
        ## æœ¬å‘¨å®è§‚ç»æµè¦ç‚¹
        
        **ç»æµå¢é•¿**: GDPå¢é•¿ç‡ {latest_data['GDP_GROWTH']:.1f}%
        **é€šèƒ€æ°´å¹³**: CPIåŒæ¯” {latest_data['CPI_GROWTH']:.1f}%
        **å°±ä¸šçŠ¶å†µ**: å¤±ä¸šç‡ {latest_data['UNEMPLOYMENT']:.1f}%
        **è´§å¸æ”¿ç­–**: è”é‚¦åŸºé‡‘åˆ©ç‡ {latest_data['FEDERAL_FUNDS_RATE']:.2f}%
        
        **å‘¨åº¦å˜åŒ–**:
        - å¤±ä¸šç‡å˜åŒ–: {latest_data['UNEMPLOYMENT'] - prev_week_data['UNEMPLOYMENT']:+.1f}%
        - åˆ©ç‡å˜åŒ–: {latest_data['FEDERAL_FUNDS_RATE'] - prev_week_data['FEDERAL_FUNDS_RATE']:+.2f}%
        """
        
        return summary
    
    def send_report(self, recipients, report):
        """å‘é€æŠ¥å‘Š"""
        msg = MIMEMultipart()
        msg['From'] = self.email
        msg['To'] = ', '.join(recipients)
        msg['Subject'] = f"å®è§‚ç»æµå‘¨æŠ¥ - {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥')}"
        
        # æ·»åŠ æŠ¥å‘Šå†…å®¹
        body = self.format_report(report)
        msg.attach(MIMEText(body, 'plain', 'utf-8'))
        
        # å‘é€é‚®ä»¶
        try:
            server = smtplib.SMTP(self.smtp_server, self.smtp_port)
            server.starttls()
            server.login(self.email, self.password)
            server.send_message(msg)
            server.quit()
            print("æŠ¥å‘Šå‘é€æˆåŠŸ")
        except Exception as e:
            print(f"æŠ¥å‘Šå‘é€å¤±è´¥: {e}")
```

## ğŸŒ Webåº”ç”¨å¼€å‘

### ğŸ¯ Flaskåº”ç”¨æ¡†æ¶

**åŸºç¡€åº”ç”¨ç»“æ„**
```python
from flask import Flask, render_template, jsonify, request
from flask_socketio import SocketIO, emit
import json

app = Flask(__name__)
app.config['SECRET_KEY'] = 'your-secret-key'
socketio = SocketIO(app, cors_allowed_origins="*")

# åˆå§‹åŒ–æ•°æ®æ”¶é›†å™¨
data_collector = MacroDataCollector()
dashboard = MacroDashboard(None)

@app.route('/')
def index():
    """ä¸»é¡µ"""
    return render_template('index.html')

@app.route('/api/data/<indicator>')
def get_data(indicator):
    """è·å–æŒ‡æ ‡æ•°æ®API"""
    try:
        data = data_collector.get_economic_indicators([indicator])
        return jsonify({
            'success': True,
            'data': data.to_dict(),
            'timestamp': datetime.now().isoformat()
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/dashboard')
def get_dashboard():
    """è·å–ä»ªè¡¨æ¿æ•°æ®"""
    try:
        # è·å–æœ€æ–°æ•°æ®
        indicators = ['GDP', 'CPIAUCSL', 'UNRATE', 'FEDFUNDS']
        data = data_collector.get_economic_indicators(indicators)
        
        # åˆ›å»ºå›¾è¡¨
        fig = dashboard.create_economic_overview()
        
        return jsonify({
            'success': True,
            'chart': fig.to_json(),
            'summary': {
                'gdp': data['GDP'].iloc[-1],
                'cpi': data['CPIAUCSL'].iloc[-1],
                'unemployment': data['UNRATE'].iloc[-1],
                'fed_funds': data['FEDFUNDS'].iloc[-1]
            }
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@socketio.on('connect')
def handle_connect():
    """WebSocketè¿æ¥å¤„ç†"""
    print('å®¢æˆ·ç«¯å·²è¿æ¥')
    
@socketio.on('disconnect')
def handle_disconnect():
    """WebSocketæ–­å¼€å¤„ç†"""
    print('å®¢æˆ·ç«¯å·²æ–­å¼€')

if __name__ == '__main__':
    socketio.run(app, debug=True, host='0.0.0.0', port=5000)
```

### ğŸ“± å‰ç«¯ç•Œé¢

**HTMLæ¨¡æ¿**
```html
<!DOCTYPE html>
<html>
<head>
    <title>å®è§‚ç»æµåˆ†æå¹³å°</title>
    <script src="https://cdn.plot.ly/plotly-latest.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/socket.io/4.0.1/socket.io.js"></script>
    <style>
        body { font-family: Arial, sans-serif; margin: 0; padding: 20px; }
        .dashboard { display: grid; grid-template-columns: 1fr 1fr; gap: 20px; }
        .card { background: #f5f5f5; padding: 20px; border-radius: 8px; }
        .indicator { text-align: center; margin: 10px 0; }
        .value { font-size: 2em; font-weight: bold; color: #333; }
        .label { color: #666; }
    </style>
</head>
<body>
    <h1>å®è§‚ç»æµåˆ†æå¹³å°</h1>
    
    <div class="dashboard">
        <div class="card">
            <h3>ç»æµæŒ‡æ ‡æ¦‚è§ˆ</h3>
            <div id="indicators-chart"></div>
        </div>
        
        <div class="card">
            <h3>å®æ—¶æŒ‡æ ‡</h3>
            <div class="indicator">
                <div class="value" id="gdp-value">--</div>
                <div class="label">GDPå¢é•¿ç‡ (%)</div>
            </div>
            <div class="indicator">
                <div class="value" id="cpi-value">--</div>
                <div class="label">CPIåŒæ¯” (%)</div>
            </div>
            <div class="indicator">
                <div class="value" id="unemployment-value">--</div>
                <div class="label">å¤±ä¸šç‡ (%)</div>
            </div>
        </div>
    </div>
    
    <script>
        // åˆå§‹åŒ–WebSocketè¿æ¥
        const socket = io();
        
        // åŠ è½½ä»ªè¡¨æ¿æ•°æ®
        async function loadDashboard() {
            try {
                const response = await fetch('/api/dashboard');
                const data = await response.json();
                
                if (data.success) {
                    // æ›´æ–°å›¾è¡¨
                    const chartData = JSON.parse(data.chart);
                    Plotly.newPlot('indicators-chart', chartData.data, chartData.layout);
                    
                    // æ›´æ–°æŒ‡æ ‡å€¼
                    document.getElementById('gdp-value').textContent = data.summary.gdp.toFixed(1);
                    document.getElementById('cpi-value').textContent = data.summary.cpi.toFixed(1);
                    document.getElementById('unemployment-value').textContent = data.summary.unemployment.toFixed(1);
                }
            } catch (error) {
                console.error('åŠ è½½ä»ªè¡¨æ¿å¤±è´¥:', error);
            }
        }
        
        // é¡µé¢åŠ è½½æ—¶åˆå§‹åŒ–
        document.addEventListener('DOMContentLoaded', function() {
            loadDashboard();
            
            // æ¯5åˆ†é’Ÿæ›´æ–°ä¸€æ¬¡
            setInterval(loadDashboard, 300000);
        });
        
        // WebSocketäº‹ä»¶å¤„ç†
        socket.on('data_update', function(data) {
            console.log('æ”¶åˆ°æ•°æ®æ›´æ–°:', data);
            loadDashboard();
        });
    </script>
</body>
</html>
```

## ğŸ› ï¸ ç³»ç»Ÿéƒ¨ç½²è¿ç»´

### â˜ï¸ äº‘ç«¯éƒ¨ç½²

**Dockeré…ç½®**
```dockerfile
# Dockerfile
FROM python:3.9-slim

WORKDIR /app

# å®‰è£…ä¾èµ–
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# å¤åˆ¶åº”ç”¨ä»£ç 
COPY . .

# æš´éœ²ç«¯å£
EXPOSE 5000

# å¯åŠ¨åº”ç”¨
CMD ["python", "app.py"]
```

**Docker Composeé…ç½®**
```yaml
# docker-compose.yml
version: '3.8'

services:
  web:
    build: .
    ports:
      - "5000:5000"
    environment:
      - FLASK_ENV=production
      - DATABASE_URL=postgresql://user:password@db:5432/macro_db
    depends_on:
      - db
      - redis
    volumes:
      - ./logs:/app/logs
      
  db:
    image: postgres:13
    environment:
      - POSTGRES_DB=macro_db
      - POSTGRES_USER=user
      - POSTGRES_PASSWORD=password
    volumes:
      - postgres_data:/var/lib/postgresql/data
      
  redis:
    image: redis:6-alpine
    ports:
      - "6379:6379"
      
  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf
    depends_on:
      - web

volumes:
  postgres_data:
```

### ğŸ“Š ç›‘æ§å’Œæ—¥å¿—

**ç³»ç»Ÿç›‘æ§**
```python
import psutil
import logging
from datetime import datetime

class SystemMonitor:
    def __init__(self):
        self.setup_logging()
        
    def setup_logging(self):
        """è®¾ç½®æ—¥å¿—è®°å½•"""
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler('system.log'),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger(__name__)
    
    def get_system_metrics(self):
        """è·å–ç³»ç»ŸæŒ‡æ ‡"""
        metrics = {
            'timestamp': datetime.now().isoformat(),
            'cpu_percent': psutil.cpu_percent(interval=1),
            'memory_percent': psutil.virtual_memory().percent,
            'disk_percent': psutil.disk_usage('/').percent,
            'network_io': psutil.net_io_counters()._asdict()
        }
        
        return metrics
    
    def check_system_health(self):
        """æ£€æŸ¥ç³»ç»Ÿå¥åº·çŠ¶æ€"""
        metrics = self.get_system_metrics()
        
        alerts = []
        
        # CPUä½¿ç”¨ç‡æ£€æŸ¥
        if metrics['cpu_percent'] > 80:
            alerts.append(f"CPUä½¿ç”¨ç‡è¿‡é«˜: {metrics['cpu_percent']:.1f}%")
        
        # å†…å­˜ä½¿ç”¨ç‡æ£€æŸ¥
        if metrics['memory_percent'] > 85:
            alerts.append(f"å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜: {metrics['memory_percent']:.1f}%")
        
        # ç£ç›˜ä½¿ç”¨ç‡æ£€æŸ¥
        if metrics['disk_percent'] > 90:
            alerts.append(f"ç£ç›˜ä½¿ç”¨ç‡è¿‡é«˜: {metrics['disk_percent']:.1f}%")
        
        # è®°å½•è­¦å‘Š
        for alert in alerts:
            self.logger.warning(alert)
        
        return {
            'status': 'healthy' if not alerts else 'warning',
            'metrics': metrics,
            'alerts': alerts
        }
```

## ğŸ¯ æœ€ä½³å®è·µ

### ğŸ”’ å®‰å…¨æ€§è€ƒè™‘

**APIå¯†é’¥ç®¡ç†**
```python
import os
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

class ConfigManager:
    def __init__(self):
        self.fred_api_key = os.getenv('FRED_API_KEY')
        self.alpha_vantage_key = os.getenv('ALPHA_VANTAGE_KEY')
        self.database_url = os.getenv('DATABASE_URL')
        
    def validate_config(self):
        """éªŒè¯é…ç½®"""
        required_vars = ['FRED_API_KEY', 'ALPHA_VANTAGE_KEY', 'DATABASE_URL']
        
        for var in required_vars:
            if not os.getenv(var):
                raise ValueError(f"ç¼ºå°‘å¿…è¦çš„ç¯å¢ƒå˜é‡: {var}")
        
        return True
```

### ğŸ“ˆ æ€§èƒ½ä¼˜åŒ–

**æ•°æ®ç¼“å­˜ç­–ç•¥**
```python
import redis
import json
from functools import wraps

class DataCache:
    def __init__(self, redis_url='redis://localhost:6379'):
        self.redis_client = redis.from_url(redis_url)
        
    def cache_data(self, key, data, ttl=3600):
        """ç¼“å­˜æ•°æ®"""
        try:
            serialized_data = json.dumps(data, default=str)
            self.redis_client.setex(key, ttl, serialized_data)
        except Exception as e:
            print(f"ç¼“å­˜å¤±è´¥: {e}")
    
    def get_cached_data(self, key):
        """è·å–ç¼“å­˜æ•°æ®"""
        try:
            cached_data = self.redis_client.get(key)
            if cached_data:
                return json.loads(cached_data)
        except Exception as e:
            print(f"è·å–ç¼“å­˜å¤±è´¥: {e}")
        return None
    
    def cache_decorator(self, ttl=3600):
        """ç¼“å­˜è£…é¥°å™¨"""
        def decorator(func):
            @wraps(func)
            def wrapper(*args, **kwargs):
                # ç”Ÿæˆç¼“å­˜é”®
                cache_key = f"{func.__name__}:{hash(str(args) + str(kwargs))}"
                
                # å°è¯•è·å–ç¼“å­˜
                cached_result = self.get_cached_data(cache_key)
                if cached_result:
                    return cached_result
                
                # æ‰§è¡Œå‡½æ•°å¹¶ç¼“å­˜ç»“æœ
                result = func(*args, **kwargs)
                self.cache_data(cache_key, result, ttl)
                
                return result
            return wrapper
        return decorator
```

## ğŸ¯ æ€»ç»“ä¸æ‰©å±•

æœ¬æŠ€æœ¯æŒ‡å—æä¾›äº†æ„å»ºå®è§‚ç»æµåˆ†æç³»ç»Ÿçš„å®Œæ•´æŠ€æœ¯æ–¹æ¡ˆã€‚é€šè¿‡è¿™äº›ä»£ç ç¤ºä¾‹å’Œæ¶æ„è®¾è®¡ï¼Œæ‚¨å¯ä»¥ï¼š

- **å»ºç«‹æ•°æ®ç®¡é“**ï¼šè‡ªåŠ¨åŒ–æ”¶é›†å’Œå¤„ç†å®è§‚ç»æµæ•°æ®
- **æ„å»ºåˆ†ææ¨¡å‹**ï¼šå¼€å‘é¢„æµ‹å’Œé£é™©è¯„ä¼°æ¨¡å‹
- **åˆ›å»ºå¯è§†åŒ–ç³»ç»Ÿ**ï¼šæ„å»ºäº¤äº’å¼çš„åˆ†æä»ªè¡¨æ¿
- **éƒ¨ç½²ç”Ÿäº§ç³»ç»Ÿ**ï¼šåœ¨äº‘ç«¯éƒ¨ç½²ç¨³å®šå¯é çš„åˆ†æå¹³å°

### ğŸš€ è¿›ä¸€æ­¥æ‰©å±•

**æœºå™¨å­¦ä¹ å¢å¼º**
- æ·±åº¦å­¦ä¹ æ¨¡å‹ç”¨äºæ—¶é—´åºåˆ—é¢„æµ‹
- è‡ªç„¶è¯­è¨€å¤„ç†åˆ†ææ–°é—»å’Œæ”¿ç­–æ–‡æœ¬
- å¼ºåŒ–å­¦ä¹ ä¼˜åŒ–æŠ•èµ„ç­–ç•¥

**å¤§æ•°æ®å¤„ç†**
- Apache Sparkç”¨äºå¤§è§„æ¨¡æ•°æ®å¤„ç†
- Kafkaç”¨äºå®æ—¶æ•°æ®æµå¤„ç†
- Elasticsearchç”¨äºå¿«é€Ÿæ•°æ®æœç´¢

**é«˜çº§åˆ†æ**
- å› æœæ¨æ–­åˆ†ææ”¿ç­–å½±å“
- ç½‘ç»œåˆ†æç ”ç©¶ç³»ç»Ÿæ€§é£é™©ä¼ æŸ“
- è´å¶æ–¯æ–¹æ³•å¤„ç†ä¸ç¡®å®šæ€§

é€šè¿‡æŒç»­å­¦ä¹ å’Œå®è·µï¼Œæ‚¨å¯ä»¥æ„å»ºæ›´åŠ å…ˆè¿›å’Œä¸“ä¸šçš„å®è§‚ç»æµåˆ†æç³»ç»Ÿï¼Œä¸ºæŠ•èµ„å†³ç­–æä¾›å¼ºæœ‰åŠ›çš„æŠ€æœ¯æ”¯æŒã€‚

---

*æœ¬æŒ‡å—æ¶µç›–äº†ä¸»è¦çš„æŠ€æœ¯å®ç°æ–¹æ¡ˆï¼Œå…·ä½“å®æ–½æ—¶è¯·æ ¹æ®å®é™…éœ€æ±‚è¿›è¡Œè°ƒæ•´å’Œä¼˜åŒ–ã€‚* 